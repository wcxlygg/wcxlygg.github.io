[{"authors":null,"categories":null,"content":"Chunxiang Wang received the B.E. degree in automation from Harbin Institute of Technology, Harbin, China, in 2019. Since September 2019, he has been a postgraduate student majoring in control science and engineering from Harbin Institute of Technology under the supervision of Prof. Huijun Gao. His research interests include image processing, object detection and tracking, real-time visual feedback for micromanipulation robots, Kalman Filter and its improvements, and robotic micromanipulation control with its biomedical applications.\n Documents:\n  For detailed CV, please click  Download my resum√©.\n  For the academic transcript and certificate for ranking, please click  Download my transcript.\n  here.\r* For the certificate for my ranking (2/182), please click here. --\r Update 09/27/2020\n","date":1549324800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://luoyeguigenno1.github.io/author/chunxiang-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chunxiang-wang/","section":"authors","summary":"Chunxiang Wang received the B.E. degree in automation from Harbin Institute of Technology, Harbin, China, in 2019. Since September 2019, he has been a postgraduate student majoring in control science and engineering from Harbin Institute of Technology under the supervision of Prof.","tags":null,"title":"Chunxiang Wang","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]]\rname = \u0026quot;Courses\u0026quot;\rurl = \u0026quot;courses/\u0026quot;\rweight = 50\r Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]]\rname = \u0026quot;Docs\u0026quot;\rurl = \u0026quot;docs/\u0026quot;\rweight = 50\r Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://luoyeguigenno1.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://luoyeguigenno1.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://luoyeguigenno1.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://luoyeguigenno1.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Chunxiang Wang","Mingsi Tong","Liqun Zhao","Songlin Zhuang","Huijun Gao"],"categories":null,"content":"","date":1598284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598284800,"objectID":"b6d0f39fff30419ccfd42928ff883bc5","permalink":"https://luoyeguigenno1.github.io/publication/daniosense-automated-high-throughput-quantification-of-zebrafish-larvae-group-movement/","publishdate":"2020-08-25T00:00:00+08:00","relpermalink":"/publication/daniosense-automated-high-throughput-quantification-of-zebrafish-larvae-group-movement/","section":"publication","summary":"Abstract: The capability to obtain detailed motility information of model organisms is fundamental to reveal their functional and social behavior characteristics. Zebrafish is a powerful vertebrate model organism. Despite recent success in the automatic quantification of adult zebrafish movement, it remains a laborious task for group zebrafish larval tracking due to their similar appearance, frequent occlusions, and highly discontinuous kinematics. This paper presents DanioSense, an automatic tracker for group larval zebrafish, to overcome these tracking challenges. The integration of a light convolutional neural network and a centerline extraction algorithm enables the tracker to localize individuals even in occlusion cases where objects‚Äô identities are prone to switch. With reliable detections, an Adaptive Kalman Filter is designed to optimally estimate locomotive parameters, which is also used for object reidentification accomplished by a two-stage data association protocol. Experimental results demonstrated a tracking accuracy of over 97%, median errors of 102 ¬µm, and 8.8‚ó¶ for the position and orientation measurement respectively, and a processing speed of over 30 frames per second with a normal computer configuration. DanioSense provides detailed quantitative data for a large-scale larvae group in nearly real time, highly boosting the efficiency of characterizing individual phenotypes and analyzing social interactions.","tags":["Under Review","Automated measurement","Multiple-object Tracking","CNN"],"title":"DanioSense Automated High-throughput Quantification of Zebrafish Larvae Group Movement   (under review)","type":"publication"},{"authors":null,"categories":null,"content":"Video tracking has become a standard procedure for studying model organisms' functional characteristics, during which the trajectory of each animal and their corresponding movement information are extracted for a range of biomedical studies, such as genetics, drug discovery, toxicology, behavioral science, etc. Manual tracking via frame-by-frame labeling is time-consuming, subjective, and tedious, whose results are often not consistent due to the fatigue and inexperience of operators. Therefore, an automatic tracking system is indispensable, which achieves a remarkedly higher research output and provides more insightful and detailed statistics.\nZebrafish larva stands out as a popular vertebrate model organism for large-scale chemical and genetic screens due to its high similarity of gene and cardiovascular system to human, optical transparency, easiness of acquisition, and rapid developmental process. Compared with other experimental organisms of zebrafish, larval motility, along with the transparent morphology, implies more phenotypic information than cells and embryos. Unlike adult zebrafish, larval relative transparency and immature nervous system allow detailed studies of gene regulation and function and neuropharmacological studies that cannot be performed in the adult period. Researchers generally transfer foreign materials into zebrafish embryos or specific organs of zebrafish larvae after which larval locomotive behaviors are recorded for further analysis. These investigations cover the fields of the analysis of movement characteristics, social behavior, and the assessment of phenotypes resulting from: gene knockdown approaches, genetic mutations, drugs, etc.\nMany single and multiple object tracking systems have been developed for adult zebrafish, reporting outstanding tracking performance. However, their performance dramatically drops when applied to a larvae group, where individuals' identities switch easily, and thus the statistical data is not usable. This weakeness highly limits the efficiency of relevant biomedical research. Over an extended period, tracking a larval zebrafish group is a labor-consuming manual work due to these systems‚Äô inability to generate reliable results.\nIt is small size, transparent and similar appearance, frequent occlusions, and discontinuous kinematics that combine to make larval tracking notoriously difficult. Small size makes a multiple-sensor tracking system and labeling approaches infeasible due to imaging and operating constraints. Transparent and similar appearance causes tracking algorithms based on extracting superficial appearance features to fail, as the difference between larvae‚Äôs appearance is much less distinguishable than that of adult fish.\nOcclusion is a general, and the toughest tracking difficulty since occluded targets are recognized as a single connected component in image, and their identities may switch after the point of overlap. This issue can be corrected according to motion continuity. However, different from the adult‚Äôs continual pattern of swimming, larvae can stay static over a long period and then flick, which is referred to as oscillatory movements. This locomotive characteristic, along with larva\u0026rsquo;s abruptly switched swim modes yields to a long-lasting occlusion where larvae can change their motion stochastically. This results in the poor performance of systems that calculate the most likely assignment of identities before and after an occlusion based on continuous motion models and body geometry.\nPresently, confronted with these tracking difficulties for larvae, the most widely-used workaround is to segregate single larva in multiwell plates physically. Another state-of-the-art solution, the well-known idTracker.ai, takes advantage of the powerful feature extracting capability of deep learning to identify objects individually. Besides, ZebraZoom and Wang et al. use background subtraction to segment and track larvae. Under certain circumstances, these methods work quite well, whereas it still seems that they have their limitations. Strictly limiting experiments to one zebrafish per dish constrains the research application as group behavior investigations, for example, cannot be performed. idTracker.ai is computationally and memory expensive, and requires a whole recording to train the neural network, which disables this method to fit in real-time, streaming applications. ZebraZoom and the method proposed by Wang et al. is only capable of processing a restricted number of larvae ($\u0026lt;$10) as their capability to tackle the occlusion problem is limited.\nThis project proposed DanioSense, an efficient, robust, and high-throughput tracking system to automate the quantification of zebrafish larvae group movement. The task of tracking group larval zebrafish is to\n discover multiple objects in individual frames;  maintain the identity information across continuous frames;  yield their trajectories while recording the statistical parameters.   The main contributions of this work include\n resolving the occlusion problem to obtain reliable trajectories with a light pre-trained convolutional neural network and a centerline extraction algorithm;  handling the discontinuous kinematics by an Adaptive Kalman Filter to obtain the optimal estimation of larvae‚Äôs locomotive parameters;  adopting an enriched vector instead of a point to generate more detailed morphology and movement statistics;  providing a variety of tracking visualization functions that offers users an intuitive sense of larval movements. In addition, DanioSense is applicable to the behavior quantification of other fish-like animals, only requiring users to upload their own datasets and retrain the convolutional neural network classifier.  There is a video which represents the performance of the algorithm here: \nFor more detailed information, please refer to this paper, which is submitted to IEEE Transactions on Automation Science and Engineering.\n Supervisor: Prof. Huijun Gao, IEEE Fellow and Professor of Department of Automation, Harbin Institute of Technology\n","date":1583107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583107200,"objectID":"f9e0283cc6a6fc2ea2061e4efcc4af0b","permalink":"https://luoyeguigenno1.github.io/project/automatic-tracking-zebrafish-larvae-in-group/","publishdate":"2020-03-02T00:00:00Z","relpermalink":"/project/automatic-tracking-zebrafish-larvae-in-group/","section":"project","summary":"In this project, a tracker that achieves efficient, robust, and high-throughput automatic quantification of zebrafish larvae group movement was proposed.","tags":["Computer Vision"],"title":"Automatic Tracking Zebrafish Larvae in Group","type":"project"},{"authors":["Gefei Zhang","Mingsi Tong"," Cheng Qian","Songlin Zhuang"," Chunxiang Wang","Huijun Gao"],"categories":null,"content":"","date":1576512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576512000,"objectID":"3efbbacbe2b1addf2960f5d056ed4d29","permalink":"https://luoyeguigenno1.github.io/publication/visual-based-contact-detection-for-automated-zebrafish-larva-heart-microinjection/","publishdate":"2019-12-17T00:00:00+08:00","relpermalink":"/publication/visual-based-contact-detection-for-automated-zebrafish-larva-heart-microinjection/","section":"publication","summary":"Abstract: This article presents an automated strategy to touch the injection site on zebrafish larva skin with the injection pipette tip accurately in the presence of water-depth variation, which is a crucial problem to automate zebrafish larva microinjection. The presented method consists of two parts: adaptive coordinate transformation and curve evolution for edge detection. In the first part, the impact of refraction is taken into consideration. An adaptive calibration method is developed, which enables the coordinate transformation matrix to adapt to the changing water depth. In the second part, the abovementioned calibration result is used to keep the injection pipette tip descending along the desired route. A curve-evolution-based edge detection algorithm is introduced to detect the deformation of larva skin caused by contact with the injection pipette tip. Experimental results demonstrate that high accuracy and success rates are achieved. The effect of uncertainties caused by water-depth variation and the skill requirement in manual manipulation are eliminated. The proposed contact detection strategy can be extended to microinjection for other organisms.","tags":["Coordinate transformation","Curve evolution","Edge detection","Microinjection"],"title":"Visual-Based Contact Detection for Automated Zebrafish Larva Heart Microinjection","type":"publication"},{"authors":null,"categories":null,"content":"Positioning the larva inside a micropipette accurately and robustly plays a pivotal role in the transportation process. The objective of this system is to transfer a larva from one location to another and adjust its posture for micromanipulation, organ imaging, drug-specific phenotypic observation, etc. A well-known relevant system is VAST BioImager, which is a modular and expandable platform that is convenient to integrate with many microscopes. A typical application of VAST BioImager is to model the skeleton bones of zebrafish larvae in a super fast speed of several seconds.\nThe setup and workflow of this system are illustrated as follows: \n Calibration. Compute the transformation matrix with the gradient-descent-based parametric identification.  Detect the object, analyse its posture. Drive the mechanical device to adjust the object to the ideal orientation. Inhale the larva into the pipette and position it to the desired position. The micromanipulator moves the pipette to the releasing position. Release larva.  The difficulties include:\n Abrupt motion in the process of aspiration or dispensing, as illustrated in the following video:  Sensitive dynamic characteristics when positioning the object, shown in the video below:  Difficulties for video tracking, including the abruptive motion, objects that are out of focus and blocked up, etc.   To deal with the object‚Äôs abrupt motion, defocus, occlusion problems, a fast and reliable tracker is designed, achieving a processing velocity of over 100 frames per second and an locating accuracy within 5 pixels.\nTo model the background, an adapted Gaussian Mixture model is adopted, with equations as follows:\n\\[p\\left( {\\vec x|{\\chi _T},BG + FG} \\right) = \\sum\\limits_{m = 1}^M {{\\pi _m}} {\\rm{N}}\\left( {\\vec x;\\overrightarrow {{\\mu _m}} ,\\sigma _m^2*I} \\right) \\]\n\\[\\begin{array}{*{20}{c}} {\\pi _m^\\prime = {\\pi _m} + \\alpha \\left( {O_m^t - {\\pi _m}} \\right)}\\\\ {\\vec \\mu _m^\\prime = {{\\vec \\mu }_m} + O_m^t\\left( {\\alpha /{\\pi _m}} \\right){{\\vec \\delta }_m}}\\\\ {\\sigma _m^{{2^\\prime }} = \\sigma _m^2 + O_m^t\\left( {\\alpha /{\\pi _m}} \\right)\\left( {\\vec \\delta _m^T{\\delta _m} - \\sigma _m^2} \\right)} \\end{array}\\]\nAfter that, subtract the frame from the background, and then the Otsu thresholding method, along with morphological operations, is performed to segment the whole contour. With the contour, the larval position is calculated, shown in the video below. \nTo model this system, the force analysis is conducted as follows: \n\\[\\begin{array}{*{20}{l}} {m{{\\ddot x}_w} + b{{\\dot x}_w} + G\\sin \\theta = {P_0}{S_{pip}} - \\frac{{{P_{air,0}}{V_{air,0}}}}{{{V_{air,0}} + u{S_{pis}} - {x_w}{S_{pip}}}}{S_{pip}}}\\\\ {m{{\\ddot x}_w} + b{{\\dot x}_w} + G\\sin \\theta = \\frac{{{P_0}{S_{pip}}{V_{air,0}} + {P_0}{S_{pip}}{S_{pis}}u - {P_0}S_{pip}^2{x_w} - {P_{air,0}}{V_{air,0}}{S_{pip}}}}{{{V_{air,0}} + u{S_{pis}} - {x_w}{S_{pip}}}}}\\\\ {m{{\\ddot x}_w} + b{{\\dot x}_w} + G\\sin \\theta = \\frac{{{P_0}{S_{pip}}{V_{air,0}} + {P_0}{S_{pip}}{S_{pis}}u - {P_0}S_{pip}^2{x_w} - {P_{air,0}}{V_{air,0}}{S_{pip}}}}{{{V_{air,0}}}}}\\\\ {m{{\\ddot x}_w} + b{{\\dot x}_w} + \\frac{{{P_0}S_{pip}^2}}{{{V_{air,0}}}}{x_w} + G\\sin \\theta = \\frac{{{P_0}{S_{pip}}{S_{pis}}}}{{{V_{air,0}}}}u + \\left( {{P_0} - {P_{air,0}}} \\right){S_{pip}}} \\end{array}\\]\nBuild the dynamic model:\n\\[\\begin{array}{*{20}{l}} {m\\ddot x + K\\ddot x + \\frac{K}{b}\\frac{{{P_0}S_{pip}^2}}{{{V_{air,0}}}}\\left( {\\frac{{m\\ddot x + G\\sin \\theta }}{K} + \\dot x} \\right) = \\frac{{K{P_0}{S_{pp}}{S_{pis}}}}{{b{V_{air,0}}}}u}\\\\ {m\\ddot x + K\\ddot x + \\frac{K}{b}\\frac{{{P_0}S_{pip}^2}}{{{V_{air,0}}}}\\frac{m}{K}\\ddot x + \\frac{K}{b}\\frac{{{P_0}S_{pip}^2}}{{{V_{air,0}}}}\\frac{{G\\sin \\theta }}{K} + \\frac{K}{b}\\frac{{{P_0}S_{pip}^2}}{{{V_{air,0}}}}\\dot x = \\frac{{K{P_0}{S_{pip}}{S_{pis}}}}{{b{V_{air,0}}}}u}\\\\ {m\\ddot x + \\left( {\\frac{{m{P_0}S_{pp}^2}}{{b{V_{air,0}}}} + K} \\right)\\ddot x + \\frac{{K{P_0}S_{pip}^2}}{{b{V_{air,0}}}}\\dot x + \\frac{{{P_0}S_{pip}^2G\\sin \\theta }}{{b{V_{ijr,0}}}} = \\frac{{K{P_0}{S_{pip}}{S_{pis}}}}{{b{V_{air,0}}}}u} \\end{array}\\]\nAbbreviate it in the fllowing form:\n\\[{a_1}\\ddot x + {a_2}\\ddot x + {a_3}\\dot x + {a_4} = bu\\]\nThe parameters of the dynamic model are identified by the frequency response test, after which the PID control algorithm is desinged, achieving the following control effect: \nThis system manages to position a larva to a desired position in the inclined micropipette for larva transfer and manipulation, which could hardly be achieved manually. Presently, the PID control effect is not optimal for larvae with different ages. Thus, I have been working on using the Adaptive Robust control to enhance the control performance, and extend its application to other organisms, such as embryo. I plan to write a paper and submit it to IEEE Transactions on Automation Science and Engineering.\n Supervisor: Prof. Huijun Gao, IEEE Fellow and Professor of Department of Automation, Harbin Institute of Technology\n","date":1575244800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575244800,"objectID":"081c7e2465d5b3a454bc4cf4e709de73","permalink":"https://luoyeguigenno1.github.io/project/zebrafish-larva-positioning-system/","publishdate":"2019-12-02T00:00:00Z","relpermalink":"/project/zebrafish-larva-positioning-system/","section":"project","summary":"In this project, a complete zebrafish larva positioning system was designed, including hardware, software, visual feedback algorithm, and control algorithm.","tags":["Computer Vision","Robotics","Control"],"title":"Zebrafish Larva Positioning System","type":"project"},{"authors":null,"categories":null,"content":"Larva yolk deformation tracking This algorithm uses optical flow to track the deformation of the zebrafish larva yolk, which serves as a visual feedback module for larva yolk soft capture.\n Cell counting This algorithm automates the task of counting the number of cells in the stem cell culture apparatus. It overcomes the uneven illumination, the low intensity between objects and background, and thin lines interference. Larva heart status monitoring After heart injection, the heart rate is often measured to evaluate the toxicity of certain drugs. This algorithm automates the monitoring process.\n  Supervisor: Prof. Huijun Gao, IEEE Fellow and Professor of Department of Automation, Harbin Institute of Technology\n","date":1572652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572652800,"objectID":"cc068f63abc0336ba4de064a67924bb9","permalink":"https://luoyeguigenno1.github.io/project/some-small-projects/","publishdate":"2019-11-02T00:00:00Z","relpermalink":"/project/some-small-projects/","section":"project","summary":"Three small computer vision projects are introduced, including larva yolk deformation tracking, cell counting, and larva heart status monitoring.","tags":["Computer Vision"],"title":"Larva yolk deformation tracking, Cell counting, and Larva heart status monitoring","type":"project"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r```\r renders as\nimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-438256971', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}\r{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\r renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\\r1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\r renders as\n$$f(k;p_0^) = \\begin{cases} p_0^ \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\r renders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\r renders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\r renders as\ngantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r An example class diagram:\n```mermaid\rclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r```\r renders as\nclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r An example state diagram:\n```mermaid\rstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r```\r renders as\nstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example\r- [x] Write diagram example\r- [ ] Do something else\r renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header |\r| ------------- | ------------- |\r| Content Cell | Content Cell |\r| Content Cell | Content Cell |\r renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}}\rA Markdown aside is useful for displaying notices, hints, or definitions to your readers.\r{{% /alert %}}\r renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}}\rYou found me!\r{{\u0026lt; /spoiler \u0026gt;}}\r renders as\n Click to view the spoiler  You found me!    Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R\r renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it üôå ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://luoyeguigenno1.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Chunxiang Wang"],"categories":[],"content":"from IPython.core.display import Image\rImage('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')\r print(\u0026quot;Welcome to Academic!\u0026quot;)\r Welcome to Academic!\r Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rcd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rjupyter lab index.ipynb\r The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n---\rtitle: My post's title\rdate: 2019-09-01\r# Put any other Academic metadata here...\r---\r Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.\r Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://luoyeguigenno1.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://luoyeguigenno1.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"The capability to directly deliver agent into the heart inside a single vertebrate is important for understanding organs activities, tissues regeneration, and developing disease models and therapeutic approaches. Despite recent success in exploiting robots to perform injection of cells, embryos, and small animals, it remains challenging to automatically achieve intracardial agent injection due to its inaccessible position, inappropriate immobilization force, and inaccurate localization. Here my labortory develops a high-throughput in vivo heart injection system which enables intracardial agent delivery of a single zebrafish larva in less than fifty seconds. This system not only consistently orients the zebrafish to a pre-designed posture but also provides a controllable capture and injection technique to regulate the deformative injury. Horizontal projection and space height of zebrafish heart are determined with micrometer resolution. To illustrate the power of our system, we have injected several classes of agents and analyzed the results which correlate well with known mechanisms of actions in mammals.\nThis video illustrates the workflow of the algorithm here (updated in 07/2019): \nThe device and schematic of the micromanipulation system is shown in the following picture. The objective of zebrafish larva morphology analysis algorithm is to\n detect the larval posture; extract its orientation and belly direction; give visual feedback to the mechanical device to rotate the object to the desired posture; calculate the inhaling position and drive the manipulator to capture the object.  The difficulties inlude\n uneven illumination; noise distractions, such as bubbles, excretion, and small particles, which could cause troubles for extracting the contour of the object; morphological variations for different objects with various ages, sizes, contours; requirements for high processing speed, which means the visual feedback algorithm needs to achive a bandwith of at least 40 fps.  This algorithm used a range of traditional image processing techniques to achieve robust, accurate, and fast morphology analysis. The workflow is illustrated as follows:\n Select the region of interest (ROI) Denoise with Gaussian filter and Gaussian filter and Gaussian bilateral filter, where the point is how to cancel the noise without eroding the contour. Confronted with this difficulty, I combine two types of filter. Adaptive thresholding to extract the foreground while address the uneven illumination. Median filterring and contour extraction. Cut the contour into two parts, compare the curvatures of each one to determine the belly side. Calculate the direction and the degree needed to rotate the object to the desired posture. The mechanical device, a stepper motor, drives the object into the ultimate position with P control. Reach the desired podture. Adaptive thresholding. Median filterring. Contour extraction. Calculate the inhaling position, painted in a red point.  This algorithms achieves\n success rate: 98% for larvae aged between 1 dpf to 4 dpf. accracy: \u0026lt;3 deg.(orientation) \u0026lt;5 pixels (inhaling point) bandwidth: \u0026gt;40 fps  It works effectively for larvae aged between 1 to 4 dpf with various morphological features. Furthermore, this project has applied for 4 patents.\n Supervisor: Prof. Huijun Gao, IEEE Fellow and Professor of Department of Automation, Harbin Institute of Technology\n","date":1543708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543708800,"objectID":"1eb24b81db94dc5267ec6403fdbd5d4f","permalink":"https://luoyeguigenno1.github.io/project/zebrafish-larvae-morphology-analysis/","publishdate":"2018-12-02T00:00:00Z","relpermalink":"/project/zebrafish-larvae-morphology-analysis/","section":"project","summary":"In this project, an image processing algorithm for zebrafish larval mophological analysis was designed, which has been put into parctice in zebrafish larva microjection system.","tags":["Computer Vision","Robotics"],"title":"Zebrafish Larva Morphology Analysis","type":"project"},{"authors":["Chunxiang Wang","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n üëâ Get Started üìö View the documentation üí¨ Ask a question on the forum üë• Chat with the community üê¶ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic üí° Request a feature or report a bug ‚¨ÜÔ∏è Updating? View the Update Guide and Release Notes ‚ù§Ô∏è Support development of Academic:  ‚òïÔ∏è Donate a coffee üíµ Become a backer on Patreon üñºÔ∏è Decorate your laptop or journal with an Academic sticker üëï Wear the T-shirt üë©‚Äçüíª Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://luoyeguigenno1.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Academic: the website builder for Hugo","type":"post"}]